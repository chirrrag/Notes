      - task: AzureCLI@2
        condition: eq('${{ parameters.destroyCluster }}', 'true')
        displayName: Destroy cluster using cluster-artifacts
        inputs:
          azureSubscription: ${{ parameters.azureSubscription }}
          scriptType: bash
          scriptLocation: inlineScript
          addSpnToEnvironment: true
          inlineScript: |
            echo "running destroy script"

            if [[ -f "$(Build.SourcesDirectory)/${{ parameters.clusterArtifactRepo }}/$(clusterName)/destroy.sh" ]]; then
              if ! (bash $(Build.SourcesDirectory)/${{ parameters.clusterArtifactRepo }}/$(clusterName)/destroy.sh)
              then
                echo "##WARNING unable to run destroy.sh for $(clusterName)"
                echo "##vso[task.setvariable variable=Destroy.Success]false"
              else
                echo "##vso[task.setvariable variable=Destroy.Success]true"
              fi
            else
                echo "##WARNING destroy.sh does not exists for $(clusterName)"
                echo "##vso[task.setvariable variable=Destroy.Success]false"
            fi
        continueOnError: false

      
      - task: AzureCLI@2
        condition: eq('${{ parameters.deletePersistentDisks }}', 'true')
        displayName: Delete disks associated with EKS cluster
        inputs:
          azureSubscription: ${{ parameters.azureSubscription }}
          scriptType: bash
          scriptLocation: inlineScript
          addSpnToEnvironment: true
          inlineScript: |
            # set -e
            # export ACCOUNT_ID=${ACCOUNT_ID}
            # export AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
            # export AWS_ROLE_ARN=${AWS_ROLE_ARN}
            # export AWS_AUTH_PATH=$(Build.SourcesDirectory)/${{ parameters.clusterArtifactRepo }}/$(clusterName)/aws-auth.sh

            # if [ ! -f ${AWS_AUTH_PATH} ]; then
            #   echo "File ${AWS_AUTH_PATH} not found"
            #   exit 1
            # fi
            # export AWS_SHARED_CREDENTIALS_FILE=$(Agent.TempDirectory)/credentials
            # export PROFILE=lightops
            # cat <<EOL > ${AWS_SHARED_CREDENTIALS_FILE}
            # [${PROFILE}]
            # credential_process = /bin/bash ${AWS_AUTH_PATH}
            # EOL

            # echo "##vso[task.setvariable variable=AWS_SHARED_CREDENTIALS_FILE]${AWS_SHARED_CREDENTIALS_FILE}"
            # echo "##vso[task.setvariable variable=PROFILE]${PROFILE}"
            

            aws sts get-caller-identity --profile  ${PROFILE}

            volumeList=$(aws ec2 describe-volumes --profile ${PROFILE} --output json --query "Volumes[?Tags[?Key=='slb.com/cluster' && Value=='${AWS_CLUSTER_ID}']]")
            echo "${volumeList}"
            if [[ -n "${volumeList}" ]]; then
                echo "Deleting volumes with the tag 'Cluster=${AWS_CLUSTER_ID}'"
                # echo "${volumeList}"

                # Iterate over the volume IDs and delete them
                for volumeId in $(echo "${volumeList}" | jq -r '.[] | .VolumeId'); do
                    echo "volume id:- ${volumeId}"
                    aws ec2 delete-volume --profile ${PROFILE} --volume-id ${volumeId} --region ${AWS_REGION} 
                done
            else
                echo "Volumes with the tag 'Cluster=${AWS_CLUSTER_ID}' were not found"
            fi
        continueOnError: false


      - task: AzureCLI@2
        displayName: Delete cluster dns record-set
        inputs:
          azureSubscription: ${{ parameters.azureSubscription }}
          scriptType: bash
          scriptLocation: inlineScript
          addSpnToEnvironment: true
          inlineScript: |
            HOSTED_ZONE_ID=$(aws route53 list-hosted-zones --profile ${PROFILE} --query "HostedZones[?Name == '${DNS_NAME}'].Id" --output text)
            echo "HOSTED ZONE ID:- ${HOSTED_ZONE_ID}"
            
            if [[ -n "${HOSTED_ZONE_ID}" ]]; then
                echo "The hosted zone '${DNS_NAME}' exists"
                # Get the resource record sets
                echo "list resource record sets"
                resource_record_sets=$(aws route53 list-resource-record-sets --profile ${PROFILE} --hosted-zone-id "${HOSTED_ZONE_ID}" --output json)
                echo "${resource_record_sets}"

                # Delete all resource record sets

                aws route53 change-resource-record-sets --profile ${PROFILE} --hosted-zone-id "${HOSTED_ZONE_ID}" --change-batch "{"Changes":[{"Action":"DELETE","ResourceRecordSet":'${resource_record_sets}'}]}"
                # Delete the hosted zone
                aws route53 delete-hosted-zone --profile ${PROFILE} --id "${HOSTED_ZONE_ID}"
                echo "Hosted zone '${HOSTED_ZONE_ID}' and all associated record sets have been deleted."
            else
                echo "The hosted zone for DNS: '${DNS_NAME}' does not exist."
            fi
        continueOnError: false

      - task: AzureCLI@2
        condition: eq('${{ parameters.deletetfstatefiles }}', 'true')
        displayName: Delete tfstate files
        inputs:
          azureSubscription: ${{ parameters.azureSubscription }}
          scriptType: bash
          scriptLocation: inlineScript
          addSpnToEnvironment: true
          inlineScript: |
            markers=$(aws s3api list-object-versions --profile ${PROFILE} --bucket "${BUCKET_NAME}" --prefix "${PREFIX}" --no-paginate --output json --query "{Objects: DeleteMarkers[].{Key:Key,VersionId:VersionId}}")
            echo "markers:- ${markers}"
            while [[ $(echo "${markers}" | jq '.Objects | length') -ne 0 ]]
            do
                aws s3api delete-objects --profile ${PROFILE} --no-paginate --no-cli-pager --bucket "${BUCKET_NAME}" --delete "${markers}"
                markers=$(aws s3api list-object-versions --profile ${PROFILE} --bucket "${BUCKET_NAME}" --no-paginate --query='{Objects: DeleteMarkers[].{Key:Key,VersionId:VersionId}}')
                echo "Removed $(echo "${markers}" | jq '.Objects | length') delete markers"
            done

            # removing objects and all their versions
            echo "object and versions"
            ObjectsandVersion=$(aws s3api list-object-versions --profile ${PROFILE} --bucket "${BUCKET_NAME}" --prefix "${PREFIX}" --no-paginate --output json --query="{Objects: Versions[].{Key:Key,VersionId:VersionId}}")
            # disable versioning on object
            echo "disable s3 bucket"
            aws s3api put-bucket-versioning --profile ${PROFILE} --bucket "${BUCKET_NAME}" --versioning-configuration Status=Suspended
            echo "print object and versions"
            echo "${ObjectsandVersion}"

            while [[ $(echo "${ObjectsandVersion}" | jq '.Objects | length') -ne 0 ]]
            do
                aws s3api delete-objects --profile ${PROFILE} --no-paginate --no-cli-pager --bucket "${BUCKET_NAME}" --delete "${ObjectsandVersion}"
                
                ObjectsandVersion=$(aws s3api list-object-versions --profile ${PROFILE} --bucket "${BUCKET_NAME}" --prefix "${PREFIX}" --no-paginate --query='{Objects: Versions[].{Key:Key,VersionId:VersionId}}')
                
                echo "Removed $(echo "${ObjectsandVersion}" | jq '.Objects | length') objects"
            done
        continueOnError: false

      - task: AzureCLI@2
        condition: eq('${{ parameters.deleteClusterPipeline }}', 'true')
        displayName: Delete cluster pipeline
        inputs:
          azureSubscription: ${{ parameters.azureSubscription }}
          scriptType: bash
          scriptLocation: inlineScript
          addSpnToEnvironment: true
          inlineScript: |
            pipeline_id=$(az pipelines show --org $(ADO_ORG) --project $(ADO_PROJECT_ID) --name  $(clusterName) | jq .id)
            if ! [[ -z "${pipeline_id}" ]]; then
              echo "Deleting pipeline for $(clusterName)"
              az pipelines delete --id ${pipeline_id} --project $(ADO_PROJECT_ID) --org $(ADO_ORG) -y
            else
              echo "No pipeline for $(clusterName) to delete"
            fi
        env:
          AZURE_DEVOPS_EXT_PAT: $(System.AccessToken)
        continueOnError: false
      - task: AzureCLI@2
        displayName: Remove url from AD application
        condition: eq('${{ parameters.removeRedirectURI }}', 'true')
        inputs:
          azureSubscription: ${{ parameters.azureSubscription }}
          scriptType: bash
          scriptLocation: inlineScript
          addSpnToEnvironment: true
          inlineScript: |
            SUB_DOMAIN=$(ZONE_NAME)
            BASE_DOMAIN=$(BASE_DOMAIN)
            resp=$(mktemp)
            patch=$(mktemp)
            az rest --method GET --uri "https://graph.microsoft.com/v1.0/applications/$(APPLICATION_OBJECT_ID)" -o json > ${resp}
            cat ${resp} | jq -e -r "del(.web.redirectUris[] | select(. == \"https://oauth2.admin.${SUB_DOMAIN}.${BASE_DOMAIN}/oauth2/callback\"))" > ${patch}
            if [[ -s "${patch}" ]]; then
              az rest --method PATCH --uri "https://graph.microsoft.com/v1.0/applications/$(APPLICATION_OBJECT_ID)" --body @${patch}
            else
              echo "Couldn't remove $(clusterName) from app registration: $(APPLICATION_OBJECT_ID)"
            fi
        continueOnError: false 
      - bash: |
          git fetch
          git checkout master
          git pull --rebase
          if [[ -d $(clusterName) ]]; then
            rm -rf $(clusterName)
            git add -u
            git commit -m 'Remove artifacts for $(clusterName) cluster'

            # push with retry
            for i in $(seq 1 $(GIT_PUSH_RETRIES)); do
              git pull --rebase
              git push && break || sleep $(GIT_PUSH_RETRY_WAIT);
            done
          else
            echo "Directory $(clusterName) does not exist"
          fi
        displayName: Delete cluster artifacts
        condition: eq('${{ parameters.deleteClusterArtifacts }}', 'true')
        workingDirectory: $(Build.SourcesDirectory)/${{ parameters.clusterArtifactRepo }}
        continueOnError: false

      - bash: |
          git fetch origin master:master
          git checkout -f master
          if [[ -d $(clusterName) ]]; then
            rm -rf $(clusterName)
            git add -u
            git commit -m 'Remove configuration for $(clusterName)'

            # push with retry
            for i in $(seq 1 $(GIT_PUSH_RETRIES)); do
              git pull --rebase origin master
              git push -u origin master && break || sleep $(GIT_PUSH_RETRY_WAIT);
            done
          else
            echo "Dedicated cluster configuration for $(clusterName) does not exist"
          fi
        displayName: Delete cluster configuration
        condition: eq('${{ parameters.deleteConfiguration }}', 'true')
        workingDirectory: $(Build.SourcesDirectory)/${{ parameters.clusterConfigurationRepo }}
        continueOnError: false

      - task: TriggerBuild@3
        displayName: "Remove app placement for cluster"
        inputs:
          buildDefinition: "ephemeral-delete-app-placements"
          useSameBranch: false
          branchToUse: master
          waitForQueuedBuildsToFinish: false
          authenticationMethod: "OAuth Token"
          password: $(System.AccessToken)
          templateParameters: >-
              ClusterId: $(clusterName)
          continueOnError: false

  

      - bash: |
          git fetch
          git checkout master
          git pull --rebase
          VAULT_REGISTRATION_PATH=$(find cluster-registry/ -name "*$(clusterName).json")
          if [[ ! -z "${VAULT_REGISTRATION_PATH}" ]]; then
            rm -f "${VAULT_REGISTRATION_PATH}"
            git add -u
            git commit -m 'Remove $(clusterName) cluster'
            # push with retry
            for i in $(seq 1 $(GIT_PUSH_RETRIES)); do
              git pull --rebase
              git push && break || sleep $(GIT_PUSH_RETRY_WAIT);
            done
          else
            echo "File $(clusterName).json not found"
          fi
        displayName: Delete vault cluster registration
        condition: eq('${{ parameters.deleteVaultConfiguration }}', 'true')
        workingDirectory: $(Build.SourcesDirectory)/vault-shared
        continueOnError: false

      - bash: |
          git checkout master
          git pull --rebase

          echo "Removing manifest for $(clusterName) cluster"
          rm -f "$(clusterName).yaml"
          git add -u
          git commit -m "Remove manifest for $(clusterName) cluster"
          # push with retry
          for i in $(seq 1 $(GIT_PUSH_RETRIES)); do
            git pull --rebase
            git push && break || sleep $(GIT_PUSH_RETRY_WAIT);
          done
        displayName: Delete cluster manifests
        condition: eq('${{ parameters.deleteClusterManifest }}', 'true')
        workingDirectory: $(Build.SourcesDirectory)/${{ parameters.clusterspecsRepo }}
